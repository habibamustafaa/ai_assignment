{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/habibamustafaa/ai_assignment/blob/main/lessons/4-ComputerVision/07-ConvNets/lab/PetFaces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPA5YaPqSEzx"
      },
      "source": [
        "# Classification of Pet's Faces\n",
        "\n",
        "Lab Assignment from [AI for Beginners Curriculum](https://github.com/microsoft/ai-for-beginners).\n",
        "\n",
        "### Getting the Data\n",
        "\n",
        "In this assignment, we will focus on relatively simple classification task - classification of pet's faces. We will use the [Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/), which contains images of 37 different breeds of dogs and cats. Let's start by downloading and visualizing the dataset.\n",
        "\n",
        "**Note:** The Oxford-IIIT Pet Dataset contains full pet images. The images will be organized by breed in the extracted folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB_vL8OjSEzz",
        "outputId": "e0aba921-53eb-428c-dfc6-00352e4eca43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-12 20:49:11--  https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz\n",
            "Resolving thor.robots.ox.ac.uk (thor.robots.ox.ac.uk)... 129.67.95.98\n",
            "Connecting to thor.robots.ox.ac.uk (thor.robots.ox.ac.uk)|129.67.95.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 308 Permanent Redirect\n",
            "Location: https://thor.robots.ox.ac.uk/pets/images.tar.gz [following]\n",
            "--2025-12-12 20:49:13--  https://thor.robots.ox.ac.uk/pets/images.tar.gz\n",
            "Reusing existing connection to thor.robots.ox.ac.uk:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 791918971 (755M) [application/octet-stream]\n",
            "Saving to: ‘images.tar.gz’\n",
            "\n",
            "images.tar.gz        64%[===========>        ] 490.65M  20.7MB/s    eta 14s    "
          ]
        }
      ],
      "source": [
        "!wget https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz\n",
        "!tar xfz images.tar.gz\n",
        "!rm images.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmMBabYMSEzz"
      },
      "source": [
        "We will define generic function to display a series of images from a list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biDPoeqmSEz0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def display_images(l,titles=None,fontsize=12):\n",
        "    n=len(l)\n",
        "    fig,ax = plt.subplots(1,n)\n",
        "    for i,im in enumerate(l):\n",
        "        ax[i].imshow(im)\n",
        "        ax[i].axis('off')\n",
        "        if titles is not None:\n",
        "            ax[i].set_title(titles[i],fontsize=fontsize)\n",
        "    fig.set_size_inches(fig.get_size_inches()*n)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zcp-LklSEz0"
      },
      "source": [
        "Now let's traverse all class subdirectories and plot first few images of each class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPoF4EcOSEz0"
      },
      "outputs": [],
      "source": [
        "# Note: The Oxford-IIIT Pet Dataset extracts to a folder named 'images'\n",
        "# Images are named by breed (e.g., 'Abyssinian_1.jpg')\n",
        "# We need to organize them into breed-specific subdirectories\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "# Organize images by breed\n",
        "if not os.path.exists('petfaces'):\n",
        "    os.makedirs('petfaces')\n",
        "    for img_file in os.listdir('images'):\n",
        "        if img_file.endswith(('.jpg', '.png')):\n",
        "            # Extract breed name from filename (everything before the last underscore and number)\n",
        "            breed = '_'.join(img_file.split('_')[:-1])\n",
        "            breed_dir = os.path.join('petfaces', breed)\n",
        "            if not os.path.exists(breed_dir):\n",
        "                os.makedirs(breed_dir)\n",
        "            os.rename(os.path.join('images', img_file), os.path.join(breed_dir, img_file))\n",
        "\n",
        "for cls in os.listdir('petfaces'):\n",
        "    print(cls)\n",
        "    display_images([Image.open(os.path.join('petfaces',cls,x))\n",
        "                    for x in os.listdir(os.path.join('petfaces',cls))[:10]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvy7s8YZSEz0"
      },
      "source": [
        "Let's also define the number of classes in our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgIhx0uPSEz1"
      },
      "outputs": [],
      "source": [
        "num_classes = len(os.listdir('petfaces'))\n",
        "num_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQhEdoPqSEz1"
      },
      "source": [
        "## Preparing dataset for Deep Learning\n",
        "\n",
        "To start training our neural network, we need to convert all images to tensors, and also create tensors corresponding to labels (class numbers). Most neural network frameworks contain simple tools for dealing with images:\n",
        "* In Tensorflow, use `tf.keras.preprocessing.image_dataset_from_directory`\n",
        "* In PyTorch, use `torchvision.datasets.ImageFolder`\n",
        "\n",
        "As you have seen from the pictures above, all of them are close to square image ratio, so we need to resize all images to square size. Also, we can organize images in minibatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIeTwEFfSEz1"
      },
      "outputs": [],
      "source": [
        "# CODE TO LOAD DATASET\n",
        "import tensorflow as tf\n",
        "\n",
        "IMAGE_SIZE = 160\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"petfaces\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"petfaces\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "num_classes = len(class_names)\n",
        "num_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_IZy5X0SEz1"
      },
      "source": [
        "Now we need to separate dataset into train and test portions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwnzmW6fSEz1"
      },
      "outputs": [],
      "source": [
        "# CODE TO DO TRAIN/TEST SPLIT\n",
        "print(\"Train batches:\", len(train_ds))\n",
        "print(\"Val batches:\", len(val_ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO1z_AMVSEz1"
      },
      "source": [
        "Now let's print the size of tensors in our dataset. If you have done everything correctly, the size of training elements should be\n",
        " * `(batch_size,image_size,image_size,3)` for Tensorflow, `batch_size,3,image_size,image_size` for PyTorch\n",
        " * `batch_size` for Labels\n",
        "\n",
        " Labels should contain numbers of classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZXXYw9nSEz2"
      },
      "outputs": [],
      "source": [
        "# Print tensor sizes\n",
        "for images, labels in train_ds.take(1):\n",
        "    print(\"Image batch shape:\", images.shape)\n",
        "    print(\"Labels batch shape:\", labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXx5gXIVSEz2"
      },
      "outputs": [],
      "source": [
        "# Display the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEVC-m3tSEz2"
      },
      "source": [
        "## Define a neural network\n",
        "\n",
        "For image classification, you should probably define a convolutional neural network with several layers. What to keep an eye for:\n",
        "* Keep in mind the pyramid architecture, i.e. number of filters should increase as you go deeper\n",
        "* Do not forget activation functions between layers (ReLU) and Max Pooling\n",
        "* Final classifier can be with or without hidden layers, but the number of output neurons should be equal to number of classes.\n",
        "\n",
        "An important thing is to get the activation function on the last layer + loss function right:\n",
        "* In Tensorflow, you can use `softmax` as the activation, and `sparse_categorical_crossentropy` as loss. The difference between sparse categorical cross-entropy and non-sparse one is that the former expects output as the number of class, and not as one-hot vector.\n",
        "* In PyTorch, you can have the final layer without activation function, and use `CrossEntropyLoss` loss function. This function applies softmax automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEf4Dq2QSEz2"
      },
      "outputs": [],
      "source": [
        "# CODE TO DEFINE NEURAL NETWORK\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(1./255, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M3vvNQwSEz2"
      },
      "source": [
        "## Train the Neural Network\n",
        "\n",
        "Now we are ready to train the neural network. During training, please collect accuracy on train and test data on each epoch, and then plot the accuracy to see if there is overfitting.\n",
        "\n",
        "> To speed up training, you need to use GPU if available. While TensorFlow/Keras will automatically use GPU, in PyTorch you need to move both the model and data to GPU during training using `.to()` method in order to take advantage of GPU acceleration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TSz1hfxSEz2"
      },
      "outputs": [],
      "source": [
        "# TRAIN THE NETWORK\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYbErpdNSEz2"
      },
      "outputs": [],
      "source": [
        "# PLOT THE ACCURACY on train and validation dataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(acc, label=\"Training Accuracy\")\n",
        "plt.plot(val_acc, label=\"Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnUt5kWaSEz3"
      },
      "source": [
        "What can you say about overfitting? What can be done to improve the accuracy of the model\n",
        "\n",
        "## Optional: Calculate Top3 Accuracy\n",
        "\n",
        "In this exercise, we were dealing with classification with quite high number of classes (35), so our result - around 50% validation accuracy - is pretty good. Standard ImageNet dataset has even more - 1000 classes.\n",
        "\n",
        "In such cases it is difficult to ensure that model **always** correctly predicts the class. There are cases when two breeds are very similar to each other, and the model returns very similar probablities (eg., 0.45 and 0.43). If we measure standard accuracy, it will be considered a wrong case, even though the model did very small mistake. This, we often measure another metric - an accuracy within top 3 most probable predictions of the model.\n",
        "\n",
        "We consider the case accurate if target label is contained within top 3 model predictions.\n",
        "\n",
        "To compute top-3 accuracy on the test dataset, you need to manually go over the dataset, apply the neural network to get the prediction, and then do the calculations. Some hints:\n",
        "\n",
        "* In Tensorflow, use `tf.nn.in_top_k` function to see if the `predictions` (output of the model) are in top-k (pass `k=3` as parameter), with respect to `targets`. This function returns a tensor of boolean values, which can be converted to `int` using `tf.cast`, and then accumulated using `tf.reduce_sum`.\n",
        "* In PyTorch, you can use `torch.topk` function to get indices of classes with highers probabilities, and then see if the correct class belongs to them. See [this](https://gist.github.com/weiaicunzai/2a5ae6eac6712c70bde0630f3e76b77b) for more hints.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIcoAwgiSEz3"
      },
      "outputs": [],
      "source": [
        "# CALCULATE TOP-3\n",
        "import tensorflow as tf\n",
        "\n",
        "correct_top3 = 0\n",
        "total = 0\n",
        "\n",
        "for images, labels in val_ds:\n",
        "    preds = model(images)\n",
        "    top3 = tf.nn.top_k(preds, k=3).indices\n",
        "\n",
        "    for i in range(len(labels)):\n",
        "        if labels[i] in top3[i]:\n",
        "            correct_top3 += 1\n",
        "        total += 1\n",
        "\n",
        "top3_accuracy = correct_top3 / total\n",
        "top3_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHaH0_UpSEz3"
      },
      "source": [
        "## Optional: Build Cats vs. Dogs classification\n",
        "\n",
        "We also want to see how accurate our binary cats vs. dogs classification would be on the same dateset. To do it, we need to adjust labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anixjsOFSEz3"
      },
      "outputs": [],
      "source": [
        "# Define dataset that contains only two labels: 0 = cat, 1 = dog\n",
        "# Hint: use class name prefix to figure out which one is which"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcqdPX4HSEz3"
      },
      "outputs": [],
      "source": [
        "# Define neural network architecture and train"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "86193a1ab0ba47eac1c69c1756090baa3b420b3eea7d4aafab8b85f8b312f0c5"
    },
    "kernelspec": {
      "display_name": "py37_pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}